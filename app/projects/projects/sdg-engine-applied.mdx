---
title: 'End-to-end tutorial for training DETR on synthetic data generated in Blender'
publishedAt: '2025-09-15'
summary: 'Explore the enduring debate between using spaces and tabs for code indentation, and why this choice matters more than you might think.'
---

I've always loved the idea of synthetic data; "unlimited power, at the tip of my finger" [1]. The idea dates back to sometime ago [2], and the applications are endless [3]; traditional ML, LLMs, Computer Vision, etc. 

While we could just go on about this alone, and the new ideas out there [4], this written piece focuses on a practical embodiment of synthetic data for Computer Vision. Specifically, an end-to-end tutorial for using Blender as a source of synthetic data for training a DEtection TRansformer (DETR) to perform real-world object detection task.

We'll use my own `sdg-engine` package to generate data to train DETR using ðŸ¤— HuggingFace's `transformers` library to detect real world objects taken from one of the Homebrew evaluation scenes, from the widely known BOP dataset [5]. Finally we'll reminisce about what we learned, the issues that remain, and other similarly hand-wavy ideas.

Let's dive right in!

## i. Picking the task: using the Homebrew open source dataset
When starting up any Machine Learning related project, one of the first questions we should ask ourselves is _"How should we evaluate the model we wish to train?"_. 

To do this, two things to keep top of mind: **collecting real-world evaluation ground truth**, and **picking our evaluation metrics**.

#### Collecting real-world evaluation ground truth
For this tutorial I've decided to go for an Open Source dataset, specifically the Homebrew BOP dataset, picking one of the scenes for simplicity [1]. This will let us move fast (as this tutorial should be bite-sized), and off-load some of the data collection to the open source community.

This dataset is perfect, it contains 4 different classes of objects, set up on a rotating platform under semi-constant lighting. The resolution of the images is `(640,420)`, and the scene itself contains close to 300 images. This scene will be easy to reproduce in Blender, as they already provide the 3D models for each of the objects in the scene! 

Let's take a quick look at the dataset:

<Image
  src="/hb-dataset-sample.gif"
  alt="Sample from the Homebrew BOP dataset showing 4 different objects on a rotating platform"
  width={480}
  height={315}
/>


To read more about the dataset, I recommend going into the source paper, as well as visiting the wider BOP website, which hosts Computer Vision datasets for all kinds of things.

Lovely, we now have our ground truth evaluation dataset.

#### Picking our evaluation metric
Computer Vision evaluation metrics are all in all some of the most annoying to set up, but luckily tend to be really well standardized and nicely defined. In our case we'll use Mean Average Precision (mAP), and for that matter we'll also care about Mean Average Recall (mAR). 

Let's break these down: _precision_ tells us from the detections our model made how well did we do, while _recall_ tells us how well we detected the number of things that should have been detected in any given image. Furthermore, we'll want to measure these over the entire dataset, so we'll first average these metrics over all detections in an image (for varying degrees of confidence), and secondly average the resulting value over all of the images in the dataset. In practice, there are more things done to the actual metric, but this is the main gist of the idea.

Great, so there we have our evaluation metrics.

## ii. Setting up synthetic data generation: using the `sdg-engine` package to generate data for said task
While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.

## iii. Making training and evaluation data available using the `datasets` library
While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.

## iv. Training and evaluating DETR using the `transformers` library
While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.

### Loading the datasets
While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.
```python
from datasets import load_dataset

# Load the synthetic dataset as your train_dataset
synthetic_dataset = load_dataset(
    "federicoarenas-ai/synthetic-bop-homebrew-scene-3-medium", 
    token=os.environ['HF_TOKEN']
    )
train_dataset = synthetic_dataset['train']
```


While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.
```python
# Load the real dataset as your test_dataset
real_dataset = load_dataset(
    "federicoarenas-ai/real-bop-homebrew-scene-3", 
    token=os.environ['HF_TOKEN']
    )
test_dataset = real_dataset['validation']
```

While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.

```python
import albumentations as A

# Our train augmentations should improve our classifiers robustness
train_transform = A.Compose(
    [
        A.LongestMaxSize(500),
        A.PadIfNeeded(500, 500, border_mode=0, value=(0, 0, 0)),
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.HueSaturationValue(p=0.5),
        A.Rotate(limit=10, p=0.5),
        A.RandomScale(scale_limit=0.2, p=0.5),
        A.GaussianBlur(p=0.5),
        A.GaussNoise(p=0.5),
    ],
    bbox_params=A.BboxParams(format="coco", label_fields=["categories"]),
)
```
While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.
```python
# Our validation augmentations should not tamper with 
# the final distribution we want to test on
test_transform = A.Compose(
    [
        A.LongestMaxSize(500),
        A.PadIfNeeded(500, 500, border_mode=0, value=(0, 0, 0)),
    ],
    bbox_params=A.BboxParams(format="coco", label_fields=["categories"]),
)
```


While we could just go on about this alone (and the new ideas out there for world models [4]). This tutorial focuses on a practical embodiment of synthetic data for Computer Vision, specifically using Blender as a source of data for training DEtection TRansformer (DETR) to perform real-world object detection task.
```
from transformers import DetrForObjectDetection, TrainingArguments
import datetime

# Prepare training run hyperparameters
RUN_IDENTIFIER = f"vit-training-run-{datetime.datetime.now().strftime('%Y-%m-%d')}"
UNIQUE_RUN_IDENTIFIER = f"vit-training-run-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}"

# Prepare model
model = DetrForObjectDetection.from_pretrained(
    checkpoint,
    id2label=ID_TO_LABEL,
    label2id=LABEL_TO_ID,
    ignore_mismatched_sizes=True,
)

# Define the training arguments
training_args = TrainingArguments(
    output_dir=UNIQUE_RUN_IDENTIFIER,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    max_steps=10000,
    save_steps=10,
    logging_steps=1,
    learning_rate=1e-5,
    weight_decay=1e-4,
    save_total_limit=2,
    remove_unused_columns=False,
    eval_steps=100,
    eval_strategy="steps",
    report_to="wandb",
    batch_eval_metrics=True,
)
```

## v. What did we learn today?

[1] Insert citation
[2] Insert citation
[3] Insert citation
[4] Insert citation